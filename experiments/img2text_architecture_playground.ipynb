{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import random\n",
    "from glob import glob\n",
    "from skimage import transform\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "\n",
    "# ensure is in parent directory\n",
    "try:\n",
    "    os.chdir(\"../../RUG-HandRec/\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "# print vocab\n",
    "print(tokenizer.vocab_size)\n",
    "inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# retrieve index of [MASK]\n",
    "mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "\n",
    "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "tokenizer.decode(predicted_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed random hidden states to the model\n",
    "hidden_states = torch.randn(1, 128, 768)\n",
    "inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_ids, hidden_states=hidden_states).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The quick brown [MASK] jumps over the lazy dog\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vocab size: \", len(tokenizer.vocab))\n",
    "# use inputs_embeds to pass in embeddings for each token\n",
    "# sample random vector\n",
    "sequence_length = 16\n",
    "embedding_size = 768\n",
    "inputs_embeds = torch.rand(1, sequence_length, embedding_size)\n",
    "\n",
    "# pay attention to only the first three \n",
    "# tokens in the sequence\n",
    "attention_mask = torch.ones(1, sequence_length)\n",
    "attention_mask[:, 3:] = 0\n",
    "\n",
    "print(\"number of parameters: \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "outputs = model(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
    "print(outputs.logits.shape)\n",
    "# get predicted token\n",
    "predicted_index = torch.argmax(outputs.logits[0, 2]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "print(predicted_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load standard bert\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "# is decoder true\n",
    "config = BertConfig(is_decoder=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel(config=config).from_pretrained('bert-base-uncased')\n",
    "\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "# Feed random input\n",
    "\n",
    "input_ids = torch.randint(0, vocab_size, (1, 32))\n",
    "# 0 is padding token, 1000 is vocab size, 16 is sequence length\n",
    "outputs = model(input_ids)\n",
    "\n",
    "print(outputs.last_hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Load the pre-trained configuration\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Set is_decoder and add_cross_attention to True\n",
    "config.is_decoder = True\n",
    "config.add_cross_attention = True\n",
    "\n",
    "# Initialize the model with the modified configuration\n",
    "decoder_bert = BertModel.from_pretrained(\"bert-base-uncased\", config=config)\n",
    "\n",
    "# Create random input_ids and attention_mask\n",
    "batch_size = 2\n",
    "sequence_length = 10\n",
    "\n",
    "input_ids = torch.randint(0, config.vocab_size, (batch_size, sequence_length))\n",
    "attention_mask = torch.ones(batch_size, sequence_length)\n",
    "\n",
    "# Create random encoder hidden states\n",
    "encoder_sequence_length = 12\n",
    "encoder_hidden_states = torch.randn(batch_size, encoder_sequence_length, config.hidden_size)\n",
    "\n",
    "# Feed the input_ids, attention_mask, and encoder hidden states into the model\n",
    "output = decoder_bert(input_ids=input_ids, attention_mask=attention_mask, encoder_hidden_states=encoder_hidden_states)\n",
    "\n",
    "# The output is a BaseModelOutputWithCrossAttentions object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "# feed in random image\n",
    "\n",
    "image = torch.rand(1, 3, 256, 256)\n",
    "output = resnet(image)\n",
    "print(output.shape)\n",
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 299, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import numpy as np\n",
    "\n",
    "# feed in ranomd signal\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# random signal \n",
    "input_values = processor(np.random.randint(-10, 10, 960), return_tensors=\"pt\").input_values\n",
    "input_values = input_values.to(torch.float32)\n",
    "logits = model(input_values).logits\n",
    "# get text\n",
    "print(logits.shape)\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "transcription"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
